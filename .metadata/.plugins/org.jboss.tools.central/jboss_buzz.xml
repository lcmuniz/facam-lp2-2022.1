<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Manage Python security with Thoth's cloud-based dependency resolver</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/07/manage-python-security-thoths-cloud-based-dependency-resolver" /><author><name>Fridolin Pokorny, Maya Costantini</name></author><id>ebf965f8-c22d-4a15-81db-4afda04fd40b</id><updated>2022-03-07T07:00:00Z</updated><published>2022-03-07T07:00:00Z</published><summary type="html">&lt;p&gt;Developers and &lt;a href="https://developers.redhat.com/topics/data-science"&gt;data scientists&lt;/a&gt; who want to build healthy and high-performance &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; applications often face challenges related to dependency management, including security risks introduced by the installation of dependencies. This article presents a quick introduction to managing Python dependencies with &lt;a href="http://thoth-station.ninja/"&gt;Project Thoth&lt;/a&gt;. The included video tutorial shows you how Thoth's cloud-based resolver finds problems in your Python dependencies and execution environment. Thoth's resolver is a drop-in replacement for other Python resolvers such as pip, Pipenv, or Poetry. Thoth's resolution process can also be used in &lt;a href="https://developers.redhat.com/topics/containers"&gt;containerized environments&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Thoth security for Python applications&lt;/h2&gt; &lt;p&gt;Containerized environments offer a way to deploy applications to cluster orchestrators such as &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. The &lt;a href="https://developers.redhat.com/articles/2021/11/25/build-and-extend-containerized-applications-project-thoth"&gt;base container image used also provides software&lt;/a&gt; that can be shipped with the application. Figure 1 shows the hardware and software underlying a typical Python application.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/stack.png?itok=dzBdBDR-" width="1154" height="697" alt="Various hardware, operating system, and Python library dependencies form the environment for an application." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. Various hardware, operating system, and Python library dependencies form the environment for an application. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Thoth can be used to discover and guide the security aspects of containerized environments through successful dependency resolution. The following video tutorial is an overview of how Thoth's cloud-based resolver resolves Python application dependencies.&lt;/p&gt; &lt;div class="video-embed-field-provider-youtube video-embed-field-responsive-video"&gt; &lt;/div&gt; &lt;h2&gt;Managing vulnerabilities with Thoth&lt;/h2&gt; &lt;p&gt;Once you have an idea of how Thoth works, you can get started using its resolver to manage your Python dependencies. Our &lt;a href="https://redhat-scholars.github.io/managing-vulnerabilities-with-thoth/managing-vulnerabilities-with-thoth/"&gt;Managing vulnerabilities with Thoth tutorial&lt;/a&gt; guides you through installing and setting up the environment for Thoth's command-line utility, &lt;a href="https://pypi.org/project/thamos/"&gt;Thamos&lt;/a&gt;. You can start by using pip to install the utility:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;pip install thamos&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once you've installed Thamos, you can &lt;a href="https://redhat-scholars.github.io/managing-vulnerabilities-with-thoth/managing-vulnerabilities-with-thoth/"&gt;follow the instructions in the tutorial&lt;/a&gt; to inspect an application present in the &lt;a href="https://github.com/thoth-station/cli-examples/"&gt;Thoth Station cli-examples&lt;/a&gt; repository. The tutorial also illustrates how to manage applications and application dependencies using the classic &lt;a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life"&gt;Game of Life application&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;git clone https://github.com/thoth-station/cli-examples cd cli-examples thamos advise&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The tutorial also presents a variety of command outputs and shows how to detect security flaws in your Python application dependencies. The &lt;a href="https://www.youtube.com/watch?v=UCt37waSa6g"&gt;linked extended video&lt;/a&gt;Â can walk you through key Thoth resolver features.&lt;/p&gt; &lt;h2&gt;Developing Project Thoth&lt;/h2&gt; &lt;p&gt;Project Thoth started as a research project in the &lt;a href="http://aicoe.ai"&gt;Artificial Intelligence Center of Excellence&lt;/a&gt; (AICoE) group in 2018. Initially, the Thoth team consisted of two engineers, but it quickly expanded with new interns and hires. From 2018 until the time of this writing, the core repositories of Project Thoth accepted contributions from 49 engineers, approximately half of them external to the Thoth team. The number of repositories associated with the &lt;a href="https://github.com/thoth-station"&gt;thoth-station organization on GitHub&lt;/a&gt; has grown to more than 180 (60 of which are now archived).&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;a href="http://thoth-station.ninja/"&gt;Project Thoth&lt;/a&gt; is also known as AIDevSecOps because of its role as part of a &lt;a href="https://developers.redhat.com/topics/devsecops"&gt;DevSecOps&lt;/a&gt; strategy.&lt;/p&gt; &lt;p&gt;To support data aggregation, we've switched our main database twice, and during the whole development phase, the project has been deployed on seven OpenShift clusters. The system generated more than 1.9 TiB of data in these clusters, which were stored in &lt;a href="https://ceph.io/"&gt;Ceph&lt;/a&gt;. The production &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; database keeps more than 27GiB of mostly Python dependency data, aggregated by &lt;a href="https://developers.redhat.com/blog/2021/04/26/continuous-learning-in-project-thoth-using-kafka-and-argo"&gt;background aggregation logic&lt;/a&gt; that uses &lt;a href="https://argoproj.github.io/argo-workflows/"&gt;Argo Workflows&lt;/a&gt; and &lt;a href="https://strimzi.io/"&gt;Strimzi&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a href="https://argo-cd.readthedocs.io"&gt;Argo CD&lt;/a&gt; helps guarantee &lt;a href="https://www.redhat.com/en/topics/devops/what-is-gitops"&gt;GitOps best practices&lt;/a&gt; and supports observability through &lt;a href="https://grafana.com/"&gt;Grafana&lt;/a&gt; and OpenShift metrics exposed by OpenShift itself. &lt;a href="https://tekton.dev/"&gt;Tekton&lt;/a&gt; and &lt;a href="https://github.com/aicoe/aicoe-ci"&gt;AICoE-CI&lt;/a&gt; help automate builds of container images that are &lt;a href="http://quay.io/organization/thoth-station"&gt;hosted on Quay&lt;/a&gt;. &lt;a href="https://github.com/kubernetes/test-infra/tree/master/prow"&gt;Prow&lt;/a&gt; checks make sure that developers deliver high-quality contributions.&lt;/p&gt; &lt;p&gt;Engineers have given &lt;a href="https://github.com/thoth-station/talks"&gt;talks about various parts of the Thoth project more than 25 times&lt;/a&gt; in North America and Europe.&lt;/p&gt; &lt;p&gt;All the statistics were aggregated as of this writing and we believe the project will continue to expand. You can learn more about Project Thoth by reading the following articles on Red Hat Developer:&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/02/24/inspecting-containerized-python-applications-cluster"&gt;Inspecting containerized Python applications in a cluster&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/01/17/how-self-host-python-package-index-using-pulp"&gt;How to self-host a Python package index using Pulp&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/01/14/extracting-dependencies-python-packages"&gt;Extracting dependencies from Python packages&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/01/05/extracting-information-python-source-code"&gt;Extracting information from Python source code&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2021/12/21/prevent-python-dependency-confusion-attacks-thoth"&gt;Prevent Python dependency confusion attacks with Thoth&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2021/11/25/build-and-extend-containerized-applications-project-thoth"&gt;Build and extend containerized applications with Project Thoth&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2021/11/17/customize-python-dependency-resolution-machine-learning"&gt;Customize Python dependency resolution with machine learning&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2021/11/04/generating-pseudorandom-numbers-python"&gt;Generating pseudorandom numbers in Python&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2021/09/29/secure-your-python-applications-thoth-recommendations"&gt;Secure your Python applications with Thoth recommendations&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2021/10/06/find-and-compare-python-libraries-project2vec"&gt;Find and compare Python libraries with project2vec&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2021/09/22/thoth-prescriptions-resolving-python-dependencies"&gt;Thoth prescriptions for resolving Python dependencies&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2021/09/17/resolve-python-dependencies-thoth-dependency-monkey"&gt;Resolve Python dependencies with Thoth Dependency Monkey&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2021/05/19/micropipenv-installing-python-dependencies-containerized-applications"&gt;micropipenv: Installing Python dependencies in containerized applications&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2021/04/26/continuous-learning-in-project-thoth-using-kafka-and-argo"&gt;Continuous learning in Project Thoth using Kafka and Argo&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2021/05/26/can-we-consider-editable-bad-practice"&gt;Can we consider --editable a bad practice?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2021/03/19/managing-python-dependencies-with-the-thoth-jupyterlab-extension"&gt;Managing Python dependencies with the Thoth JupyterLab extension&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2020/12/24/use-kebechet-machine-learning-to-perform-source-code-operations"&gt;Use Kebechet machine learning to perform source code operations&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2020/09/30/ai-software-stack-inspection-with-thoth-and-tensorflow"&gt;AI software stack inspection with Thoth and TensorFlow&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2019/10/28/microbenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth"&gt;Microbenchmarks for AI applications using Red Hat OpenShift on PSI in project Thoth&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Connect with the Thoth team!&lt;/h2&gt; &lt;p&gt;As part of Project Thoth, we are accumulating knowledge to help Python developers create healthy applications. If you would like to follow updates, feel free to subscribe to our &lt;a href="https://www.youtube.com/channel/UClUIDuq_hQ6vlzmqM59B2Lw"&gt;YouTube channel&lt;/a&gt; or follow us on the &lt;a href="https://twitter.com/thothstation"&gt;@ThothStation&lt;/a&gt; Twitter handle.&lt;/p&gt; &lt;p&gt;Even though the project is in its early stages, we are constantly improving its stability and reliability. We would be happy for any feedback. To send us feedback or get involved in improving the Python ecosystem, please contact the Thoth Station &lt;a href="https://github.com/thoth-station/support"&gt;support repository&lt;/a&gt;. You can also directly reach out to the &lt;a href="https://twitter.com/ThothStation"&gt;Thoth team on Twitter&lt;/a&gt;. You can report any issues you've spotted in open source Python libraries to the support repository or &lt;a href="https://developers.redhat.com/articles/2021/09/22/thoth-prescriptions-resolving-python-dependencies"&gt;directly write prescriptions for the resolver&lt;/a&gt; and send them to our &lt;a href="https://github.com/thoth-station/prescriptions/"&gt;prescriptions repository&lt;/a&gt;. By participating in these ways, you can help the Python cloud-based resolver come up with better recommendations for the whole Python community.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/07/manage-python-security-thoths-cloud-based-dependency-resolver" title="Manage Python security with Thoth's cloud-based dependency resolver"&gt;Manage Python security with Thoth's cloud-based dependency resolver&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Fridolin Pokorny, Maya Costantini</dc:creator><dc:date>2022-03-07T07:00:00Z</dc:date></entry><entry><title type="html">DevOpsDays Raleigh 2022 - Talking Architecture Shop (accepted)</title><link rel="alternate" href="http://www.schabell.org/2022/03/devopsdays-raleigh-2022-talking-architecture-shop-accepted.html" /><author><name>Eric D. Schabell</name></author><id>http://www.schabell.org/2022/03/devopsdays-raleigh-2022-talking-architecture-shop-accepted.html</id><updated>2022-03-07T06:00:00Z</updated><content type="html">Â I've thatÂ I was trying to join the DevOpsDays Raleigh 2022 conference this year, to be hosted on April 13-14 in Raleigh, NC.Â  I submitted a few talks, a workshop, and crossed my fingers to await the selection committee results. The verdict is in, I've got a session talking architecture shop selected. It's going to be fun to share my teams research and development of open source DevOps architectures. Here's the talk and abstract and really looking forward to seeing you all in person! My session is from a series calledÂ Talking Architecture Shop. This is focusing on architecture research for solutions in the DevOps domain that scale and will be co-presented with my good friend . TALKING ARCHITECTURE SHOP - EXPLORING OPEN SOURCE DEVOPS AT SCALEÂ  You've heard of large scale open source architectures, but have you ever wanted to take a serious look at these real life enterprise DevOps implementations that scale? This session takes attendees on a tour of multiple use cases covering DevOps challenges with hybrid cloud management with GitOps, DevOps in healthcare, and much more. Not only are these architectures interesting, but they are successful real life implementations featuring open source technologies and power many of your own online experiences. The attendee departs this session with a working knowledge of how to map general open source technologies to their solutions. Material covered is available freely online and attendees can use these solutions as starting points for aligning to their own solution architectures. Join us for an hour of power as we talk architecture shop!Â  Finally, remember toÂ Â and join the fun for a really interesting array of DevOps talks and workshops.Â </content><dc:creator>Eric D. Schabell</dc:creator></entry><entry><title type="html">Narayana Community Priorities</title><link rel="alternate" href="https://jbossts.blogspot.com/2022/03/narayana-community-priorities.html" /><author><name>Michael Musgrove</name></author><id>https://jbossts.blogspot.com/2022/03/narayana-community-priorities.html</id><updated>2022-03-04T13:24:00Z</updated><content type="html">NARAYANA COMMUNITY PRIORITIES The following is an outline of our near term priorities for the Narayana open source transaction manager. They have been set based on input from the community, including the narayana-users . It is not necessarily a complete list, so please continue to share your own thoughts on whether you agree they are the right focus for the project, in some respects the list is quite ambitious and we encourage/need and welcome continued contributions and discussion from the community to help achieve these goals. COMMUNITY ENGAGEMENT 1. Improve inclusiveness by building a community of users: * produce clear guidance on how to contribute with different levels of guidance * responsive to the community (PRs, queries, issues, rooms etc) * issue labels for new contributors and for tasks that we need help with * make sure all new features are publicised (blog, articles, docs, etc) * regular blog posts with runnable and focused examples * acknowledge contributors in release announcements * encourage discussions in the community (i.e. minimise private team discussions) JAVA VERSIONS 1. : this work is already well under way. Java SE 11 is now the minimum runtime supported by WildFly and Jakarta EE compatible implementations. 2. (i.e. SE 11 will the minimum supported version) and add INTEGRATING CONTEMPORARY SERVICES: 1. 2. . This task depends on CLOUD STRATEGY: 1. 2. An improved cloud strategy for JTA around recovery (again we have already started work in this area). Currently we need to create a bespoke solution for every cloud, e.g. the . This task includes provision of a more âcloud readyâ transaction log store. The task still needs to be pinned down but some relevant input material includes: 1. (this includes an investigation of whether an Infinispan based store is feasible - note that earlier versions were incompatible with our needs) 2. 3. 4. 5. There is also the forum item: which will help with using Narayana in cloud deployments: * the task should also explore the pros and cons of storing it for crash recovery purposes * the forum thread also includes some work that we may do on validating our current uid solution for cloud environments 3. Better integration of LRA in cloud environments: 1. 2. TRANSACTION LOG STORES 1. Persistent Memory: narayana already provides a pmem based object store which we would like to 2. 3. to our own Object Store locking (FileLock.java) for managing concurrent access to a transaction log. It should be configurable at runtime or build time (Quarkus is a good use case). If the runtime platform does not provide the capability then a default fallback mechanism will be defined. UPGRADES/DEPRECATION/REMOVAL/REPLACEMENT OF EXISTING FUNCTIONALITY: 1. Remove in favour of using . We are tracking this work using . 2. Remove - it was previously deprecated by the . The issue tracker is 3. 4. Upgrade to JUnit 5 (from 4) for unit testing: OTHER 1. Improved support for asynchronous APIs. Although we continue to be tied to XA and very few resource managers support the asynchronous component of the , there are still things we would like to do in this area including</content><dc:creator>Michael Musgrove</dc:creator></entry><entry><title type="html">WildFly on the Cloud with Helm</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/openshift/wildfly-on-the-cloud-with-helm/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/openshift/wildfly-on-the-cloud-with-helm/</id><updated>2022-03-04T10:58:22Z</updated><content type="html">Helm is a package Manager that simplify the management of manifest resources you need for Kubernetes projects. In this article we will walk through an example WildFly application which we will deploy on OpenShift using Helm Charts Helm overview and setup Helm charts can simplify the complexities of dependency management for a Kubernetes project. With ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Data conversion in Pandas dataframes: 3 approaches to try</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/04/data-conversion-pandas-dataframes-3-approaches-try" /><author><name>adkulkarni</name></author><id>7d4d9045-c1e4-4e80-be88-366d3762e9fc</id><updated>2022-03-04T07:00:00Z</updated><published>2022-03-04T07:00:00Z</published><summary type="html">&lt;p&gt;I have been working on data analysis for almost three years, and there are some starters that I think are essential for every data analyst using the popularÂ &lt;a href="https://pandas.pydata.org"&gt;Pandas&lt;/a&gt;Â library for &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt;. If you often do data transformations in Pandas, you know how annoying it can be to search the web for basic information every time you get started with a new dataframe.&lt;/p&gt; &lt;p&gt;For me, one of those sore points is encoding text data. For some reason, I can never remember a good way to encode data when I need it. So, I decided to note down my three favorite ways of doing so. Let me know in the comments if you have any other alternatives.&lt;/p&gt; &lt;h2&gt;1. Using the replace method with a dictionary&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;replace&lt;/code&gt; method is great for manipulating column data in a Pandas dataframe. You can define a dictionary as an input argument for this method when converting a column of text data to integers. Let's take the simple dataframe called &lt;code&gt;data&lt;/code&gt; with two columns, one text and one Boolean:&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="500"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class="text-align-center" scope="col"&gt;Index&lt;/th&gt; &lt;th class="text-align-center" scope="col"&gt;shouldihaveanothercoffee&lt;/th&gt; &lt;th class="text-align-center" scope="col"&gt;isitfridayyet&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;always&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;sure&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;definitely&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;You can convert the &lt;code&gt;shouldihaveanothercoffee&lt;/code&gt; column to a numerical column using the replace method as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;data["shouldihaveanothercoffee"].replace({"always":0, "sure":1, "definitely":2}, inplace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following table shows the output from that statement:&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="401"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class="text-align-center" scope="col"&gt;Index&lt;/th&gt; &lt;th class="text-align-center" scope="col"&gt;shouldihaveanothercoffee&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;2. Using the astype method&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;astype&lt;/code&gt; method can convert data from one type to another. Boolean values to integers. Here, I'll show how you can use the method to convert a Boolean column &lt;code&gt;isitfridayyet&lt;/code&gt; in the previously shown dataframe to Integer values (&lt;code&gt;True&lt;/code&gt; being treated as &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;False&lt;/code&gt; as &lt;code&gt;0&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt; &lt;code&gt;data["isitfridayyet"] = data["isitfridayyet"].astype(int)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following table shows the output from that statement:&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="401"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class="text-align-center" scope="col"&gt;Index&lt;/th&gt; &lt;th class="text-align-center" scope="col"&gt;isitfridayyet&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;3. Using the apply method&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;apply&lt;/code&gt; method is another convenient method to handle data modifications for a data frame. You can use this method with explicit type conversion and the lambda function to convert data from Boolean to integer:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;data["isitfridayyet"] = data["isitfridayyet"].apply(lambda x: int(x)) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following table shows the output from that statement:&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="401"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class="text-align-center" scope="col"&gt;Index&lt;/th&gt; &lt;th class="text-align-center" scope="col"&gt;isitfridayyet&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;References&lt;/h2&gt; &lt;p&gt;I hope these suggestions help you with your next Pandas project. Feel free to leave comments or questions on this article to discuss the methods or tell me what other methods I missed.&lt;/p&gt; &lt;p&gt;Useful documentation on the methods I've discussed can be found here:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html"&gt;pandas.DataFrame.replace&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html"&gt;pandas.DataFrame.astype&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html"&gt;pandas.DataFrame.apply&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/04/data-conversion-pandas-dataframes-3-approaches-try" title="Data conversion in Pandas dataframes: 3 approaches to try"&gt;Data conversion in Pandas dataframes: 3 approaches to try&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>adkulkarni</dc:creator><dc:date>2022-03-04T07:00:00Z</dc:date></entry><entry><title type="html">Editing Serverless Workflow definitions with our new VSCode extension</title><link rel="alternate" href="https://blog.kie.org/2022/03/editing-serverless-workflow-definitions-with-our-new-vscode-extension.html" /><author><name>Paulo Martins</name></author><id>https://blog.kie.org/2022/03/editing-serverless-workflow-definitions-with-our-new-vscode-extension.html</id><updated>2022-03-03T21:32:40Z</updated><content type="html">We are happy to announce the first release of our , which allows users to have a side-by-side real-time preview of their workflows while editing JSON and YAML files inside VSCode (*.sw.json, *.sw.yaml, *.sw.yml). This extension complies with the CNCF specification v0.8. FEATURES INCLUDED In this first release we are delivering the following features: REAL-TIME DIAGRAM PREVIEW RENDERING The diagram on the right side of the editor is updated on each change made, providing the user quick feedback on their modifications. If the workflow is invalid, the preview will have some transparency and be frozen since the last valid state. AUTOMATIC SVG GENERATION By default, the extension saves an SVG file in the same directory as the workflow file. If you want to change that, you can check the extension configuration options, where you will be able to deactivate it or customize the file name and directory where the file is saved. AUTO-COMPLETE SUGGESTIONS In this version, the editor provides basic auto-complete suggestions based on the specification and the expressions used in the current file. NEXT STEPS For the next releases, we are already working on several new features that will improve what the user can do inside the editor: SERVICE CATALOG Users will be able to register Open API endpoints in their environment, allowing the editor to provide augmentation options to make it easy to add new functions to the workflow. AUTO-COMPLETE SUGGESTIONS ENHANCEMENT Besides showing suggestions based on the specification and the current file expressions, the user will also be able to add functions and its parameters quickly by selecting suggestions linked to their service catalog. VALIDATION Inline detailed validation and integration with the VSCodeâs Validation UI, which will provide a detailed list of errors and warnings of the workflow. -------------------------------------------------------------------------------- That is all for now, the extension is already available at the . And stay tuned for our next releases! The post appeared first on .</content><dc:creator>Paulo Martins</dc:creator></entry><entry><title type="html">Prototypes and Live Queries: A Sneak Peek Into The Future of Drools (featuring Debezium and Apache Calcite)</title><link rel="alternate" href="https://blog.kie.org/2022/03/prototypes-and-live-queries-a-sneak-peek-into-the-future-of-drools-featuring-debezium-and-apache-calcite.html" /><author><name>Mario Fusco</name></author><id>https://blog.kie.org/2022/03/prototypes-and-live-queries-a-sneak-peek-into-the-future-of-drools-featuring-debezium-and-apache-calcite.html</id><updated>2022-03-03T11:31:41Z</updated><content type="html">Drools is a hybrid rule engine, allowing both data-driven forward chaining (rules match facts in the working memory producing other facts that in turn activate other rules) and goal-driven backward chaining (queries match facts in the working memory, eventually invoking other queries to retrieve them). This second usage pattern is also available in streaming mode through which allow attaching a listener for change events instead of returning an iterable result set. This feature allows to create incremental materialized views of the facts inserted in the working memory and then it makes Drools a good fit to analyze and aggregate live streams of data. For instance this could be applied to the stream of changes generated by a change data capture tool like .Â  Moreover it would be nice to have the possibility of querying Drools not only in DRL, but also using a more standard and well known query language like SQL. This is possible by using a tool to parse and analyze SQL query like and translating the results of this analysis into a Drools query. I put these ideas together in a to demonstrate how this could work. In particular in Iâm simulating the output stream produced by Debezium in json format by incrementally inserting into my query engine messages like the following { Â Â Â "before":null, Â Â Â "after":{ Â Â Â Â Â  "id":1001, Â Â Â Â Â  "first_name":"Sally", Â Â Â Â Â  "last_name":"Thomas", Â Â Â Â Â  "email":"sally.thomas@acme.com" Â Â Â }, Â Â Â "source":{ Â Â Â Â Â  "version":"1.8.0.Alpha2", Â Â Â Â Â  "connector":"postgresql", Â Â Â Â  "name":"dbserver1", Â Â Â Â Â  "snapshot":"true", Â Â Â Â Â  "db":"postgres", Â Â Â Â Â  "schema":"inventory", Â Â Â Â Â  "table":"customers", Â Â Â }, Â Â Â "op":"r", Â Â Â "ts_ms":1643708392757, Â Â Â "transaction":null } What Debezium does is setting the before field of this json to null and populate the after if a new record has been inserted, doing the opposite if it has been deleted and populating both fields if it has been updated, so Iâm inserting, removing or updating facts into the Drools session .Â  Note that the facts inserted in the engine cannot be plain pojos since there doesnât exist any Java class modeling them. For this reason they are modeled with structural typing as s, a into Drools. Here the types of the different facts ingested by the rule engine is no longer determined by their Java classes, but simply by a logical name that in this case coincides with the name of the table of the record to be processed. As anticipated my other goal was having the possibility to query this system with like the following SELECT * FROM customers c LEFT JOIN addresses a on c.id = a.customer_id To achieve this, in a first iteration, I used Calcite to simply parse the SQL query and visit the resulting AST to defined through the . Then I realized that Calcite can do much more than simply parsing the SQL query: it also analyzes the query, producing the corresponding . This analysis provides a normalized and optimized view of the SQL query, so I wrote a of my transformer from SQL to Drools queries that is feeded by the relational algebra produced by Calcite.Â  with the generated by Debezium that I used in my test and that simply outputs the incremental matches to the transformed SQL query found by Drools, produces an output like the following rowInserted: Â Â Â customers: {last_name=Thomas, id=1001, first_name=Sally, email=sally.thomas@acme.com}; Â Â Â addresses: {city=Hamburg, street=42 Main Street, id=100001, customer_id=1001} --- 0 rowInserted: Â Â Â customers: {last_name=Thomas, id=1001, first_name=Sally, email=sally.thomas@acme.com}; Â Â Â addresses: {city=Berlin, street=11 Post Dr., id=100002, customer_id=1001} --- 1 rowInserted: Â Â Â customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com}; Â Â Â addresses: {city=Los Angeles, street=12 Rodeo Dr., id=100003, customer_id=1002} --- 2 rowInserted: Â Â Â customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com}; Â Â Â addresses: {city=Monterey, street=1 Debezium Plaza, id=100004, customer_id=1002} --- 3 rowInserted: Â Â Â customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com}; Â Â Â addresses: {city=Monterey, street=2 Debezium Plaza, id=100005, customer_id=1002} rowUpdated: Â Â Â customers: {last_name=Thomas, id=1001, first_name=Sarah, email=sally.thomas@acme.com}; Â Â Â addresses: {city=Berlin, street=11 Post Dr., id=100002, customer_id=1001} rowUpdated: Â Â Â customers: {last_name=Thomas, id=1001, first_name=Sarah, email=sally.thomas@acme.com}; Â Â Â addresses: {city=Hamburg, street=42 Main Street, id=100001, customer_id=1001} --- 4 rowDeleted: Â Â Â customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com}; Â Â Â addresses: {city=Los Angeles, street=12 Rodeo Dr., id=100003, customer_id=1002} rowDeleted: Â Â Â customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com}; Â Â Â addresses: {city=Monterey, street=2 Debezium Plaza, id=100005, customer_id=1002} rowDeleted: Â Â Â customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com}; Â Â Â addresses: {city=Monterey, street=1 Debezium Plaza, id=100004, customer_id=1002} --- 5 In a similar way the test provides also a second use case, this time , demonstrating how this implementation also works with it. In my opinion this proof of concept demonstrates the flexibility of Drools and its ability to efficiently process and aggregate data. The recent introduction of prototypes extends these capabilities even in cases when these data are structured but untyped as discussed in this article. The post appeared first on .</content><dc:creator>Mario Fusco</dc:creator></entry><entry><title>REST API error modeling with Quarkus 2.0</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/03/rest-api-error-modeling-quarkus-20" /><author><name>Stephen Nimmo</name></author><id>9833bd66-12c9-4dad-ac2c-390cc83dd6e1</id><updated>2022-03-03T07:00:00Z</updated><published>2022-03-03T07:00:00Z</published><summary type="html">&lt;p&gt;In the &lt;a href="https://developers.redhat.com/articles/2022/01/01/quarkus-ground-customer-api-revisited"&gt;previous installment of the Quarkus from the ground up series&lt;/a&gt;, you saw the beginnings of a fully functional, &lt;a href="https://www.openapis.org/"&gt;OpenAPI-compliant&lt;/a&gt; REST &lt;a href="https://developers.redhat.com/topics/api-management/"&gt;API&lt;/a&gt; built using &lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt;. That article covered all of the architectural layers, from managing database schemas with &lt;a href="https://flywaydb.org/"&gt;Flyway&lt;/a&gt; to building the API itself with &lt;a href="https://quarkus.io/guides/resteasy-reactive"&gt;RESTEasy Reactive&lt;/a&gt;. You saw happy-path use cases, but didn't get into the concepts around error handling. In this article, you'll dive into error handling, build a solid error response model, and see how you can help API consumers reduce toil in their work.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; Once you're ready to dive in, you can &lt;a href="https://github.com/quarkus-ground-up/customer-api/tree/0.0.2"&gt;download the complete source code for this article&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Why error handling matters&lt;/h2&gt; &lt;p&gt;Error handling is one of those aspects of a system's architecture that deserves more attention. When you're designing a new feature, most of the discussion centers on what happens when things go rightâbut when that feature goes into production, most of the attention is focused on what is going wrong. As is true with observability and other architectural concerns, if the development team spent a bit more time upfront in the design of error handling within an application, they could reap considerable rewards in production in terms of application availability and stability.&lt;/p&gt; &lt;h2&gt;Out-of-the-box functionality&lt;/h2&gt; &lt;p&gt;Before modeling and implementing error handling into the sample application, it would be good to explore what error responses look like without any additional code. Begin by &lt;a href="https://github.com/quarkus-ground-up/customer-api"&gt;cloning the repository&lt;/a&gt; for the application you developed in the last article. Next, you'll need to create a new test that uses &lt;a href="https://site.mockito.org/"&gt;Mockito&lt;/a&gt; to create a response with an unexpected runtime exception. To use Mockito, you need to add the Quarkus extension:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; &lt;dependency&gt; &lt;groupId&gt;io.quarkus&lt;/groupId&gt; &lt;artifactId&gt;quarkus-junit5-mockito&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The test creates a mocked &lt;code&gt;CustomerService&lt;/code&gt; instance configured to throw a &lt;code&gt;RuntimeException&lt;/code&gt;. When the response is returned, extract it as a &lt;code&gt;Response&lt;/code&gt; object and set a breakpoint to better understand what the returned JSON structure looks like:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; package com.redhat.exception; import com.redhat.customer.CustomerService; import io.quarkus.test.junit.QuarkusTest; import io.quarkus.test.junit.mockito.InjectMock; import io.restassured.response.Response; import org.junit.jupiter.api.Test; import org.mockito.Mockito; import static io.restassured.RestAssured.given; @QuarkusTest public class ThrowableMapperTest { @InjectMock CustomerService customerService; @Test public void throwUnexpectedRuntimeExceptionInCustomerService() { Mockito.when(customerService.findAll()).thenThrow(new RuntimeException("Completely Unexpected")); Response errorResponse = given() .when() .get("/customers") .then() .statusCode(500) .extract().response(); errorResponse.prettyPrint(); } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here's the response JSON structure:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; { "details": "Error id 327095e1-b8fa-491e-b3f1-e8944bd8023c-1, java.lang.RuntimeException: Completely Unexpected", "stack": "java.lang.RuntimeException: Completely Unexpected\n\tat com.redhat.customer.CustomerService_ClientProxy.findAll(Unknown Source)\n\tat com.redhat.customer.CustomerResource.get(CustomerResource.java:43)\n\tat com.redhat.customer.CustomerResource$quarkusrestinvoker$get_458c9ef52b4c83180ab57cf43ffebc046fc42b84.invoke(Unknown Source)\n\tat org.jboss.resteasy.reactive.server.handlers.InvocationHandler.handle(InvocationHandler.java:29)\n\tat org.jboss.resteasy.reactive.server.handlers.InvocationHandler.handle(InvocationHandler.java:7)\n\tat org.jboss.resteasy.reactive.common.core.AbstractResteasyReactiveContext.run(AbstractResteasyReactiveContext.java:141)\n\tat io.quarkus.vertx.core.runtime.VertxCoreRecorder$13.runWith(VertxCoreRecorder.java:543)\n\tat org.jboss.threads.EnhancedQueueExecutor$Task.run(EnhancedQueueExecutor.java:2449)\n\tat org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1478)\n\tat org.jboss.threads.DelegatingRunnable.run(DelegatingRunnable.java:29)\n\tat org.jboss.threads.ThreadLocalResettingRunnable.run(ThreadLocalResettingRunnable.java:29)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.base/java.lang.Thread.run(Thread.java:833)" } &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;This response is pretty gnarly, and the API consumer would have to perform a ton of parsing to get useful information out of it. The &lt;code&gt;stack&lt;/code&gt; field also leaks information about our implementation, which is a security problem. While the framework has transformed a &lt;code&gt;RuntimeException&lt;/code&gt; into a well-formed HTTP response with the proper HTTP status code, the result is unusable.&lt;/p&gt; &lt;h3&gt;Out of the box: ConstraintViolationException&lt;/h3&gt; &lt;p&gt;Now that you've seen the results of an unexpected exception, let's take a look at the constraint violation use case. This application uses the &lt;a href="https://hibernate.org/validator/"&gt;Hibernate Validator&lt;/a&gt; framework to validate data objects as they are passed between layers. The &lt;code&gt;Customer&lt;/code&gt; object has &lt;code&gt;@NotEmpty&lt;/code&gt; validations on both the &lt;code&gt;firstName&lt;/code&gt; and &lt;code&gt;lastName&lt;/code&gt; fields, along with an &lt;code&gt;@Email&lt;/code&gt; validator on the &lt;code&gt;email&lt;/code&gt; field that will validate the value of the &lt;code&gt;String&lt;/code&gt; as a well-formed email address if present. When the method parameter for the &lt;code&gt;Customer&lt;/code&gt; object has a &lt;code&gt;@Valid&lt;/code&gt; annotation, the validator framework will perform the validations. If any constraint violations are present, the framework will throw the &lt;code&gt;ConstraintViolationException&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To see what happens out of the box, you can temporarily create a new test based on one of the existing tests. This temporary test will send a &lt;code&gt;Customer&lt;/code&gt; object with a null &lt;code&gt;firstName&lt;/code&gt; field:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; @Test public void postFailNoFirstNameResponse() { Customer customer = createCustomer(); customer.setFirstName(null); Response errorResponse = given() .contentType(ContentType.JSON) .body(customer) .post() .then() .statusCode(400) .extract().response(); errorResponse.prettyPrint(); } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here's the JSON response:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; { "title": "Constraint Violation", "status": 400, "violations": [ { "field": "post.customer.firstName", "message": "must not be empty" } ] } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;While it's a vast improvement over the unexpected runtime exception case, the structure and content are still insufficient. The response structure is too specific to the underlying implementation. You want a more generic design that can handle all error responses.&lt;/p&gt; &lt;h2&gt;Update the validation messages&lt;/h2&gt; &lt;p&gt;Building a better error response model begins with the error messages. How you implement those messages will depend on your need for internationalization. If your API is scoped for use in a single language, the annotations themselves can use &lt;a href="https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/#section-message-interpolation"&gt;default message interpolation&lt;/a&gt; by passing a message parameter to the annotation. This method supports building messages using &lt;a href="https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/#section-interpolation-with-message-expressions"&gt;message expressions&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt; @NotEmpty(message = "Customer's first name is required.") private String firstName; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If your application needs to support internationalization, you should use message properties files. Name these files using the pattern &lt;code&gt;ValidationMessages_loc.properties&lt;/code&gt;, substituting the appropriate locale abbreviation (&lt;code&gt;en&lt;/code&gt;, &lt;code&gt;es&lt;/code&gt;, etc.) for &lt;code&gt;loc&lt;/code&gt;, so developers can build &lt;a href="https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/#section-resource-bundle-locator"&gt;message bundles&lt;/a&gt; for every language. Here's an example of the &lt;code&gt;ValidationMessages.properties&lt;/code&gt; file, the default, non-locale-specific message bundle placed in the &lt;code&gt;src/main/resources&lt;/code&gt; folder:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; System.error=An unexpected error has occurred. Please contact support. Customer.firstName.required=Customer's first name is required Customer.lastName.required=Customer's last name is required Customer.email.invalid=Customer's email address is invalid &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With this method, you can use the keys of the message bundle to express the correct validation message as part of the annotation:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; @NotEmpty(message = "{Customer.firstName.required}") private String firstName; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once you've implemented this response model, your response JSON content will contain much more helpful error messages:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; { "title": "Constraint Violation", "status": 400, "violations": [ { "field": "post.customer.firstName", "message": "Customer's first name is required" } ] } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that you have taken care of the error message aspect of the application, you can restructure the error response.&lt;/p&gt; &lt;h2&gt;Model the error response&lt;/h2&gt; &lt;p&gt;Modeling the error response can be a point of contention in application architecture because no full-featured standards govern the response structure. There have been some attempts at standardization, such as a Request for Comments (RFC) published in 2016 called &lt;a href="https://datatracker.ietf.org/doc/html/rfc7807"&gt;Problem details for HTTP APIs&lt;/a&gt;. This RFC is a good start for standardizing things like the field names of the response structure. However, the design doesn't easily support common use cases like the constraint violation, so the result is a collection of errors for a single response.&lt;/p&gt; &lt;p&gt;When it comes to modeling errors, developers must choose between multiple structures or a single unified structure. Using multiple structures requires the consumer to perform introspection on the error structure to determine where the data resides. In contrast, a single suitable structure requires the consumer to create an implied model where the cardinality of the messages is the focal point. Here's are a couple of examples of how an error structure response might be modeled:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; // System Error Response - Single { "errorId": "971e0747-f7ec-4d21-915b-c66257db05c3", "message": "An unexpected error has occurred. Please contact support" } // System Error Response - Multiple { "errorId": "971e0747-f7ec-4d21-915b-c66257db05c3", "errors": [ { "message": "An unexpected error has occurred. Please contact support" } ] } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For this article, we will focus on creating a single unified error response structure. This structure should handle both application and system errors, whether they are expected or not:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; package com.redhat.exception; import com.fasterxml.jackson.annotation.JsonInclude; import lombok.EqualsAndHashCode; import lombok.Getter; import java.util.List; @Getter @EqualsAndHashCode public class ErrorResponse { @JsonInclude(JsonInclude.Include.NON_NULL) private String errorId; private List&lt;ErrorMessage&gt; errors; public ErrorResponse(String errorId, ErrorMessage errorMessage) { this.errorId = errorId; this.errors = List.of(errorMessage); } public ErrorResponse(ErrorMessage errorMessage) { this(null, errorMessage); } public ErrorResponse(List&lt;ErrorMessage&gt; errors) { this.errorId = null; this.errors = errors; } public ErrorResponse() { } @Getter @EqualsAndHashCode public static class ErrorMessage { @JsonInclude(JsonInclude.Include.NON_NULL) private String path; private String message; public ErrorMessage(String path, String message) { this.path = path; this.message = message; } public ErrorMessage(String message) { this.path = null; this.message = message; } public ErrorMessage() { } } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Some implementation notes:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The application uses &lt;a href="https://projectlombok.org/"&gt;Lombok&lt;/a&gt; to manage the boilerplate code, as in the previous article in this series. &lt;ul&gt;&lt;li&gt;The &lt;code&gt;@Getter&lt;/code&gt; annotation creates getters for the class variables and the &lt;code&gt;@EqualsAndHashCode&lt;/code&gt; annotation autogenerates the &lt;code&gt;equals&lt;/code&gt; and &lt;code&gt;hashCode&lt;/code&gt; methods using a default methodology in which all class variables are used for both implementations.&lt;/li&gt; &lt;li&gt;As mentioned in the last article, you should use libraries such as Lombok with extreme care. These annotations can sometimes create generated implementations with easily hidden performance or runtime execution impacts.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;The &lt;code&gt;@JsonInclude(JsonInclude.Include.NON_NULL)&lt;/code&gt; &lt;a href="https://fasterxml.github.io/jackson-annotations/javadoc/2.9/com/fasterxml/jackson/annotation/JsonInclude.html"&gt;annotation&lt;/a&gt; provides instructions to not serialize the item if it is null.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Catching Throwable: Introduction to the ExceptionMapper&lt;/h2&gt; &lt;p&gt;Now that you have the data structure for the error response, you can begin to model how to handle exceptions in the application. In Quarkus, you can use the &lt;a href="https://jakarta.ee/specifications/platform/9/apidocs/jakarta/ws/rs/ext/exceptionmapper"&gt;JAX-RS ExceptionMapper&lt;/a&gt; class to perform the necessary transformations between exceptions and your error response.&lt;/p&gt; &lt;p&gt;The exception mapper infrastructure starts by catching &lt;a href="https://cr.openjdk.java.net/~iris/se/11/latestSpec/api/java.base/java/lang/Throwable.html"&gt;Throwable&lt;/a&gt;, which is the ultimate superclass of all errors and exceptions, checked and unchecked. By catching &lt;code&gt;Throwable&lt;/code&gt; in an &lt;code&gt;ExceptionMapper&lt;/code&gt;, you can ensure that all unexpected exceptions can be caught, processed, logged, and transformed to the &lt;code&gt;ErrorResponse&lt;/code&gt;. This will eliminate the unwanted behavior in which an unexpected exception might leak stack traces and other internals back to the consumer.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; package com.redhat.exception; import lombok.extern.slf4j.Slf4j; import javax.ws.rs.core.Response; import javax.ws.rs.ext.ExceptionMapper; import javax.ws.rs.ext.Provider; import java.util.ResourceBundle; import java.util.UUID; @Provider @Slf4j public class ThrowableMapper implements ExceptionMapper&lt;Throwable&gt; { @Override public Response toResponse(Throwable e) { String errorId = UUID.randomUUID().toString(); log.error("errorId[{}]", errorId, e); String defaultErrorMessage = ResourceBundle.getBundle("ValidationMessages").getString("System.error"); ErrorResponse.ErrorMessage errorMessage = new ErrorResponse.ErrorMessage(defaultErrorMessage); ErrorResponse errorResponse = new ErrorResponse(errorId, errorMessage); return Response.status(Response.Status.INTERNAL_SERVER_ERROR).entity(errorResponse).build(); } } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Some implementation notes:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The implementation uses the &lt;a href="https://projectlombok.org/features/log"&gt;Lombok &lt;code&gt;@Slf4j&lt;/code&gt;&lt;/a&gt; annotation to create a private, final, and static reference to a log variable that uses the Simple Logging Facade for Java (&lt;a href="https://www.slf4j.org/"&gt;SLF4J&lt;/a&gt;).&lt;/li&gt; &lt;li&gt;&lt;code&gt;ResourceBundle.getBundle("ValidationMessages")&lt;/code&gt; allows you to get a specific error message from the configured validation messages. You'll learn more about the details of this when you dive into the constraint violation exception scenario in the next section.&lt;/li&gt; &lt;li&gt;In the &lt;code&gt;toResponse&lt;/code&gt; method, a unique identifier for the error is created using &lt;a href="https://docs.oracle.com/javase/8/docs/api/java/util/UUID.html"&gt;UUID&lt;/a&gt;. This identifier is used when generating the log statements to facilitate debugging in a production environment. If you pass the unique identifier back to the consumer, the consumer can then reference the identifier in a support ticket, which the support team can use to quickly search the logs and identify what the cause of the error might be.&lt;/li&gt; &lt;li&gt;Once the error is logged, it is then transformed into the &lt;code&gt;ErrorResponse&lt;/code&gt; object and returned to the consumer with an HTTP status code of 500, denoting a generic internal server error.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;ConstraintViolationExceptionMapper&lt;/h2&gt; &lt;p&gt;Now, consider the constraint violation use case once again. What you would like to see is a response message body produced with an array of error messages. To model this, you can use the existing &lt;code&gt;ErrorResponse&lt;/code&gt; and write a new &lt;code&gt;ConstraintViolationExceptionMapper&lt;/code&gt; to handle the specific exception:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; package com.redhat.exception; import javax.validation.ConstraintViolationException; import javax.ws.rs.core.Response; import javax.ws.rs.ext.ExceptionMapper; import javax.ws.rs.ext.Provider; import java.util.List; import java.util.stream.Collectors; @Provider public class ConstraintViolationExceptionMapper implements ExceptionMapper&lt;ConstraintViolationException&gt; { @Override public Response toResponse(ConstraintViolationException e) { List&lt;ErrorResponse.ErrorMessage&gt; errorMessages = e.getConstraintViolations().stream() .map(constraintViolation -&gt; new ErrorResponse.ErrorMessage(constraintViolation.getPropertyPath().toString(), constraintViolation.getMessage())) .collect(Collectors.toList()); return Response.status(Response.Status.BAD_REQUEST).entity(new ErrorResponse(errorMessages)).build(); } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With both of these mechanisms in place, the error response body is exactly what you're looking for:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;{ "errors": [ { "path": "post.customer.lastName", "message": "Customer's last name is required" }, { "path": "post.customer.email", "message": "Customer's email address is invalid" }, { "path": "post.customer.firstName", "message": "Customer's first name is required" } ] }&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Why your enterprise should standardize its error model&lt;/h2&gt; &lt;p&gt;Using the common &lt;code&gt;ErrorResponse&lt;/code&gt; object and creating &lt;code&gt;ExceptionMapper&lt;/code&gt; implementations for all of your use cases gives you a unified and easily consumable API error model. This approach works great for an individual team; however, another problem arises when all of the development teams in an enterprise design their error models independently and end up with different naming conventions and structures, especially in a polyglot world. The API consumers, whether they are other &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt; or front-end developers building UIs, end up toiling over the myriad of different error responses.&lt;/p&gt; &lt;p&gt;This is a great opportunity for enterprise standardization. Bringing together the API teams in a common &lt;a href="https://www.atlassian.com/agile/agile-at-scale/spotify"&gt;guild&lt;/a&gt; allows everyone in the company to come together in building and publishing a common standard for error responses. This eliminates toil on the API consumer end and reduces API development work by utilizing existing, documented response structures and even building shared libraries for use across teams.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/03/rest-api-error-modeling-quarkus-20" title="REST API error modeling with Quarkus 2.0"&gt;REST API error modeling with Quarkus 2.0&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Stephen Nimmo</dc:creator><dc:date>2022-03-03T07:00:00Z</dc:date></entry><entry><title>Introduction to the Node.js reference architecture, Part 7: Code coverage</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/02/introduction-nodejs-reference-architecture-part-7-code-coverage" /><author><name>Lucas Holmquist</name></author><id>6a3f46c3-86a3-484e-8052-10e2e69868ef</id><updated>2022-03-02T07:00:00Z</updated><published>2022-03-02T07:00:00Z</published><summary type="html">&lt;p&gt;In this article, we'll look at why testing in &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; applications is important. You'll also learn how to measure code coverage, how to maximize your investment in testing, and what the &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview"&gt;Node.js reference architecture&lt;/a&gt;Â recommends to ensure adequate code coverage.Â &lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Read the other articles in our Node.js reference architecture series so far&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Part 1: &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview"&gt;Overview of the Node.js reference architecture&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 2: &lt;a href="https://developer.ibm.com/languages/node-js/blogs/nodejs-reference-architectire-pino-for-logging/"&gt;Logging in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2021/05/17/introduction-nodejs-reference-architecture-part-3-code-consistency"&gt;Code consistency in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 4: &lt;a href="https://developers.redhat.com/articles/2021/06/22/introduction-nodejs-reference-architecture-part-4-graphql-nodejs"&gt;GraphQL in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 5: &lt;a href="https://developers.redhat.com/articles/2021/08/26/introduction-nodejs-reference-architecture-part-5-building-good-containers"&gt;Building good containers&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 6: &lt;a href="https://developers.redhat.com/articles/2021/12/03/introduction-nodejs-reference-architecture-part-6-choosing-web-frameworks"&gt;Choosing web frameworks&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Part 7: Code coverage&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;What is code coverage?&lt;/h2&gt; &lt;p&gt;Code coverage is a software testing metric that determines how much code in a project has been successfully validated under a test procedure, which in turn, helps in analyzing how thoroughly software has been verified.&lt;/p&gt; &lt;p&gt;To measure the lines of code that are actually exercised by test runs, the code coverage metric takes various criteria into consideration. The following are a few important coverage criteria.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Function coverage:&lt;/strong&gt; The functions in the source code that are called and executed at least once.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Statement coverage:&lt;/strong&gt; The number of statements that have been successfully validated in the source code.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Path coverage: &lt;/strong&gt;The flows containing a sequence of controls and conditions that have worked well at least once.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Branch or decision coverage:&lt;/strong&gt; The decision control structures (loops, for example) that have executed properly.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Condition coverage:&lt;/strong&gt; The Boolean expressions that are validated and that execute both &lt;code&gt;TRUE&lt;/code&gt; and &lt;code&gt;FALSE&lt;/code&gt; during the test runs.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;What modules should you use for code coverage?&lt;/h2&gt; &lt;p&gt;If you've read theÂ &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview"&gt;previous installments in the Node.js reference architecture series&lt;/a&gt;, you know that we recommend modules that our teams are familiar with and use regularly. This article is no different. The teams defining the reference architecture have decided on two modules that we recommend for code coverage:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://www.npmjs.com/package/nyc"&gt;nyc&lt;/a&gt;, probably the most popular tool for code coverage. One of the main reasons this module is the most popular is that it works well with most JavaScript testing frameworks. &lt;code&gt;nyc&lt;/code&gt; is the successor command-line interface (CLI) for &lt;code&gt;istanbul&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.npmjs.com/package/jest"&gt;Jest&lt;/a&gt;, which generates coverage when you run the tool with the &lt;code&gt;--coverage&lt;/code&gt; option.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;This article's examples use &lt;code&gt;nyc&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Testing example&lt;/h2&gt; &lt;p&gt;Download the example from the &lt;a href="https://github.com/nodeshift-blog-examples/ref-arch-code-coverage"&gt;Nodeshift example repository&lt;/a&gt;. The example is made up of two simple functions located in the &lt;code&gt;index.js&lt;/code&gt; file, and a test in the &lt;code&gt;test&lt;/code&gt;Â directory that uses the &lt;a href="https://mochajs.org/"&gt;Mocha test runner&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The first function adds two numbers:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-javascript"&gt;function addTwoNumbers(x, y) { return x + y; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This function can be easily covered by this simple test:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-javascript"&gt;describe('testing for coverage', () =&gt; { it ('should add 2 numbers correctly', () =&gt; { assert.equal(addTwoNumbers(1,1), 2); }); });&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Code coverage can be generated easily too: Just call the &lt;code&gt;nyc&lt;/code&gt; module in conjunction with our test to generate the coverage report.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;package.json&lt;/code&gt; might look something like this to run our tests while generating coverage reports:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;"scripts": { "test": "mocha", "coverage": "nyc npm run test" }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Executing&lt;code&gt; npm run coverage&lt;/code&gt; is all that is needed. Because we wrote only one test, our statement coverage will be only about 18%. To increase code coverage, we have to test the other functionsÂ  and statements:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt; testing for coverage â should add 2 numbers correctly 1 passing (3ms) ----------|---------|----------|---------|---------|------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ----------|---------|----------|---------|---------|------------------- All files | 18.18 | 0 | 50 | 18.18 | index.js | 18.18 | 0 | 50 | 18.18 | 9-23 ----------|---------|----------|---------|---------|------------------- &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once the other tests are written and run, code coverage should be at 100%:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;testing for coverage â should add 2 numbers correctly â should test that phish is the best band â should test the beatles are a good band too â should test that nickelback is not that good â should test that all other bands are pretty good 5 passing (6ms) ----------|---------|----------|---------|---------|------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ----------|---------|----------|---------|---------|------------------- All files | 100 | 100 | 100 | 100 | index.js | 100 | 100 | 100 | 100 | ----------|---------|----------|---------|---------|-------------------&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;What to cover&lt;/h2&gt; &lt;p&gt;After much discussion, the reference architecture team's guidance on what to cover is broken down into two sections:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Coverage for modules:&lt;/strong&gt; It is important to cover all public APIs. Basically, any exposed API that a user can interact with should be covered.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Coverage for applications:&lt;/strong&gt; This coverage should be driven by the key user stories and key paths that the application can take. Unlike a module, here it is much more important to test and cover paths that are critical for your application than to worry about covering all paths.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Acceptable coverage thresholds&lt;/h2&gt; &lt;p&gt;We realized in our discussions that not all projects are created equal. Some projects might be starting from scratch, whereas others contain legacy code bases.&lt;/p&gt; &lt;p&gt;For new projects without legacy code, a good percentage threshold is about 70%. This is because, with new projects, it is relatively easy to add tests while creating the application or module.&lt;/p&gt; &lt;p&gt;It might be a little harder to add coverage to a project that is older and doesn't have any coverage yet, because adding tests to old code with technical debt can be a challenge, especially for someone new coming into the project. In this case, a good percentage threshold is about 30%.&lt;/p&gt; &lt;p&gt;It is also our experience that when adding coverage to an older code base, focusing on the key user stories gives you the best return on your investment. Focusing on the path and branch/decision coverage can also maximize the investment required to get to 30%.&lt;/p&gt; &lt;h2&gt;Guidance for open source projects&lt;/h2&gt; &lt;p&gt;For free and &lt;a href="https://developers.redhat.com/topics/open-source"&gt;open source&lt;/a&gt; projects, it might be helpful to post the results of the coverage to an external service, such as &lt;a href="https://coveralls.io/"&gt;Coveralls&lt;/a&gt;. Creating issues that suggest ways to increase code coverage could be a way to attract contributors to the project.&lt;/p&gt; &lt;p&gt;It is also common to report the coverage increase or decrease percentage during a pull request or merge request CI run. In our experience, it is best to use this information in a code review rather than by blocking a merge.&lt;/p&gt; &lt;h2&gt;What's next?&lt;/h2&gt; &lt;p&gt;We cover new topics regularly as part of the &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/"&gt;Node.js reference architecture series&lt;/a&gt;. While you wait for the next installment, we invite you to visit the &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture"&gt;Node.js reference architecture repository&lt;/a&gt; on GitHub, where you'll see the work we've already done and the kinds of topics you can look forward to in the future.&lt;/p&gt; &lt;p&gt;To learn more about what Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js topic page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/02/introduction-nodejs-reference-architecture-part-7-code-coverage" title="Introduction to the Node.js reference architecture, Part 7: Code coverage"&gt;Introduction to the Node.js reference architecture, Part 7: Code coverage&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Lucas Holmquist</dc:creator><dc:date>2022-03-02T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus 2.7.3.Final released - Maintenance release</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-2-7-3-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-7-3-final-released/</id><updated>2022-03-02T00:00:00Z</updated><content type="html">Today, we released a new maintenance release for our 2.7 release train: 2.7.3.Final. Thanks to all the people reporting issues, providing reproducers, fixesâ¦ , itâs really appreciated. It is a safe upgrade for anyone already using 2.7. If you are not using 2.7 already, please refer to the 2.7 migration guide....</content><dc:creator>Guillaume Smet</dc:creator></entry></feed>
